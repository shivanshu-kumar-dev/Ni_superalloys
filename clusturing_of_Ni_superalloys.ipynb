{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5C75QaZ1TcwV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xlrd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(input_file):\n",
        "    # Load data from an Excel file\n",
        "    source_data = pd.read_excel(input_file)\n",
        "    np_data = source_data.iloc[:,:].values\n",
        "    return source_data, np_data"
      ],
      "metadata": {
        "id": "Pz3S9d2JUPOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(np_data):\n",
        "    from sklearn import preprocessing\n",
        "    # Normalize data using Min-Max scaling\n",
        "    array_data = np.zeros(np_data.shape)\n",
        "    for i in range(np_data.shape[1]):\n",
        "        array_data[:, i] = preprocessing.minmax_scale(np_data[:, i])\n",
        "    return array_data"
      ],
      "metadata": {
        "id": "nvCSSiY-UWET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_split(array_data):\n",
        "    # Select data for clustering, excluding the first and last column\n",
        "    return array_data[:, 1:-1]"
      ],
      "metadata": {
        "id": "IqkYm1EpUeYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cluster(train_data, np_data, source_data):\n",
        "    from sklearn.cluster import KMeans\n",
        "    # Initialize and fit the KMeans model\n",
        "    model = KMeans()\n",
        "    model.fit(train_data)\n",
        "    # Store labels from KMeans model\n",
        "    labels = model.labels_"
      ],
      "metadata": {
        "id": "fWCEZMk8UiPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine = np.concatenate((np_data, labels[:, None]), axis=1)\n",
        "    writer = pd.ExcelWriter('cluster_data2.xls')"
      ],
      "metadata": {
        "id": "gDg2fmI1UosS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and save labels data into Excel\n",
        "    r0 = pd.concat([pd.DataFrame(np_data[:, 0:2]), pd.DataFrame(labels)], axis=1)\n",
        "    r0.columns = ['temp', 'stress', 'label']\n",
        "    r0.to_excel(writer, sheet_name='cluster_label')"
      ],
      "metadata": {
        "id": "3cGsA9XTUp-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and save each cluster's data into Excel\n",
        "    for i in range(len(np.unique(labels))):\n",
        "        cluster_subset = combine[combine[:, -1] == i][:, :-1]\n",
        "        r0 = pd.DataFrame(range(len(cluster_subset[:, 0])))\n",
        "        r1 = pd.DataFrame(cluster_subset)\n",
        "        r = pd.concat([r0, r1], axis=1)\n",
        "        r.columns = ['alloy'] + list(source_data.columns)\n",
        "        r.to_excel(writer, sheet_name='cluster_' + str(i))\n",
        "    plot_cluster(train_data, labels)\n",
        "    writer.save()"
      ],
      "metadata": {
        "id": "5yY5-otmUtYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cluster(data_zs, labels):\n",
        "    from sklearn.manifold import TSNE\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Embed high-dimensional data into 2D using t-SNE\n",
        "    tsne = TSNE()\n",
        "    tsne_embedding = tsne.fit_transform(data_zs)\n",
        "    tsne = pd.DataFrame(tsne_embedding)\n",
        "\n",
        "    # Plot clusters using different colors\n",
        "    for i, color in enumerate(['k.', 'r.', 'y.', 'g.', 'c.', 'm.', 'b.', '#EE82EE']):\n",
        "        d = tsne[labels == i]\n",
        "        plt.plot(d[0], d[1], color)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ljaeq3v-Ux9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cluster():\n",
        "    print(\"Starting the clustering process...\")\n",
        "    resource_data, np_data = load_data('multi_scale_samples_revision.xlsx')\n",
        "    array_data = data_process(np_data)\n",
        "    train_data = cluster_split(array_data)\n",
        "    train_cluster(train_data, array_data, resource_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print('Welcome to the world of clustering!')\n",
        "    run_cluster()"
      ],
      "metadata": {
        "id": "BC_Em1PXU6FH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}